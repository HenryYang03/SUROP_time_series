{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51119d7382670f1",
   "metadata": {},
   "source": [
    "# GRU Model with Decay Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.096612Z",
     "start_time": "2024-08-17T22:55:38.093712Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11206d8a00b7cdcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.657910Z",
     "start_time": "2024-08-17T22:55:38.116703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_x = pd.read_csv('/Users/mohanyang/Documents/GitHub/SUROP_time_series/SUROP/data/train_x.csv')\n",
    "train_y = pd.read_csv('/Users/mohanyang/Documents/GitHub/SUROP_time_series/SUROP/data/train_y.csv')\n",
    "test_x = pd.read_csv('/Users/mohanyang/Documents/GitHub/SUROP_time_series/SUROP/data/test_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8848f19ab8badcaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.666684Z",
     "start_time": "2024-08-17T22:55:38.658880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hour  ID    Age  Gender  Unit1  Unit2     HR   O2Sat   Temp     SBP  ...  \\\n",
      "0     1   2  66.67     1.0    0.0    1.0  74.78  100.06  35.61  121.68  ...   \n",
      "1     2   2  66.67     1.0    0.0    1.0  74.78  100.06  35.61  121.68  ...   \n",
      "2     3   2  66.67     1.0    0.0    1.0  74.78  100.06  35.61  121.68  ...   \n",
      "3     4   2  66.67     1.0    0.0    1.0  74.78  100.06  35.61  121.68  ...   \n",
      "4     5   2  66.67     1.0    0.0    1.0  84.42   99.58  35.61  114.60  ...   \n",
      "\n",
      "   Phosphate  Potassium  Bilirubin_total  TroponinI    Hct   Hgb  PTT   WBC  \\\n",
      "0        NaN       4.48              NaN        NaN  28.83  9.21  NaN  8.15   \n",
      "1        NaN       4.48              NaN        NaN  28.83  9.21  NaN  8.15   \n",
      "2        NaN       4.48              NaN        NaN  28.83  9.21  NaN  8.15   \n",
      "3        NaN       4.48              NaN        NaN  28.83  9.21  NaN  8.15   \n",
      "4        NaN       4.48              NaN        NaN  28.83  9.21  NaN  8.15   \n",
      "\n",
      "   Fibrinogen  Platelets  \n",
      "0         NaN        NaN  \n",
      "1         NaN        NaN  \n",
      "2         NaN        NaN  \n",
      "3         NaN        NaN  \n",
      "4         NaN        NaN  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "(482010, 40)\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "print(train_x.head())\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780add8981ad9955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.669320Z",
     "start_time": "2024-08-17T22:55:38.667295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Outcome\n",
      "0   2        0\n",
      "1   3        0\n",
      "2   5        1\n",
      "3   6        0\n",
      "4  13        0\n",
      "(12115, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.head())\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f42e6abd239289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.678532Z",
     "start_time": "2024-08-17T22:55:38.670424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of hours: 336\n"
     ]
    }
   ],
   "source": [
    "max_hours = train_x.groupby('ID')['Hour'].count().max()\n",
    "print(f'Maximum number of hours: {max_hours}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64be0cb97c0c0bf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.683510Z",
     "start_time": "2024-08-17T22:55:38.679068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get unique person IDs\n",
    "person_ids = train_x['ID'].unique()\n",
    "\n",
    "# Initialize tensors for features, masks, and time intervals\n",
    "num_persons = len(person_ids)\n",
    "num_features = train_x.shape[1] - 2  # excluding 'ID' and 'Hour' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7175c1c823f814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.686040Z",
     "start_time": "2024-08-17T22:55:38.684034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,     3,     5, ..., 21630, 21632, 21633])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "845478173d527d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:38.688013Z",
     "start_time": "2024-08-17T22:55:38.686564Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize tensors\n",
    "X_tensor = np.zeros((num_persons, max_hours, num_features))\n",
    "M_tensor = np.zeros((num_persons, max_hours, num_features))\n",
    "Delta_tensor = np.zeros((num_persons, max_hours, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd4c27fb4e6951a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:42.716671Z",
     "start_time": "2024-08-17T22:55:38.688581Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, person_id in enumerate(person_ids):\n",
    "    person_data = train_x[train_x['ID'] == person_id].sort_values('Hour')\n",
    "    hours = person_data['Hour'].values\n",
    "    features = person_data.drop(columns=['ID', 'Hour']).values\n",
    "    \n",
    "    # Fill X_tensor\n",
    "    X_tensor[i, :len(hours), :] = features\n",
    "    \n",
    "    # Fill M_tensor (masking)\n",
    "    M_tensor[i, :len(hours), :] = ~np.isnan(features)\n",
    "    \n",
    "    # Fill Delta_tensor (time intervals)\n",
    "    for t in range(1, len(hours)):\n",
    "        for f in range(num_features):\n",
    "            Delta_tensor[i, t, f] = (hours[t] - hours[t-1]) + Delta_tensor[i, t-1, f] * (1 - M_tensor[i, t-1, f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9e167e59aed66a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:55:42.717828Z",
     "start_time": "2024-08-17T22:55:42.717783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 66.67,   1.  ,   0.  , ...,   8.15,    nan,    nan],\n",
       "        [ 66.67,   1.  ,   0.  , ...,   8.15,    nan,    nan],\n",
       "        [ 66.67,   1.  ,   0.  , ...,   8.15,    nan,    nan],\n",
       "        ...,\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ]],\n",
       "\n",
       "       [[ 79.74,   0.  ,   0.  , ...,   6.82, 267.01, 281.18],\n",
       "        [ 79.74,   0.  ,   0.  , ...,   6.82, 267.01, 281.18],\n",
       "        [ 79.74,   0.  ,   0.  , ...,   6.82, 267.01, 281.18],\n",
       "        ...,\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ]],\n",
       "\n",
       "       [[ 60.74,   1.  ,    nan, ...,  12.45,    nan,  84.77],\n",
       "        [ 60.74,   1.  ,    nan, ...,  12.45,    nan,  84.77],\n",
       "        [ 60.74,   1.  ,    nan, ...,  12.45,    nan,  84.77],\n",
       "        ...,\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 65.41,   1.  ,   0.  , ...,  21.87,    nan, 303.89],\n",
       "        [ 65.41,   1.  ,   0.  , ...,  21.87,    nan, 303.89],\n",
       "        [ 65.41,   1.  ,   0.  , ...,  21.87,    nan, 303.89],\n",
       "        ...,\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ]],\n",
       "\n",
       "       [[ 58.61,   1.  ,    nan, ...,  45.9 ,    nan, 302.32],\n",
       "        [ 58.61,   1.  ,    nan, ...,  45.9 ,    nan, 302.32],\n",
       "        [ 58.61,   1.  ,    nan, ...,  45.9 ,    nan, 302.32],\n",
       "        ...,\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ]],\n",
       "\n",
       "       [[ 58.58,   1.  ,   1.  , ...,  17.02,    nan, 167.  ],\n",
       "        [ 58.58,   1.  ,   1.  , ...,  17.02,    nan, 167.  ],\n",
       "        [ 58.58,   1.  ,   1.  , ...,  17.02,    nan, 167.  ],\n",
       "        ...,\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "        [  0.  ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a26ac8cc092b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., ..., 1., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 0., ..., 1., 0., 1.],\n",
       "        [1., 1., 0., ..., 1., 0., 1.],\n",
       "        [1., 1., 0., ..., 1., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 0., ..., 1., 0., 1.],\n",
       "        [1., 1., 0., ..., 1., 0., 1.],\n",
       "        [1., 1., 0., ..., 1., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55636ca501ff55ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 2., 2.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 2., ..., 1., 2., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 2., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 2., ..., 1., 2., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 2., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Delta_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fa8ed6cceb3e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12115, 336, 38) (12115, 336, 38) (12115, 336, 38)\n"
     ]
    }
   ],
   "source": [
    "# Replace NaNs with zeros in X_tensor (not necessary in M_tensor and Delta_tensor)\n",
    "X_tensor = np.nan_to_num(X_tensor)\n",
    "\n",
    "print(X_tensor.shape, M_tensor.shape, Delta_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41512dbd553e7a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12115, 1)\n"
     ]
    }
   ],
   "source": [
    "# Ensure train_y is aligned with X_tensor\n",
    "labels = np.zeros(len(person_ids))\n",
    "\n",
    "for i, person_id in enumerate(person_ids):\n",
    "    if person_id in train_y['ID'].values:\n",
    "        labels[i] = train_y[train_y['ID'] == person_id]['Outcome'].values[0]\n",
    "\n",
    "labels = labels.reshape(-1, 1)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7a4b86aa34fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, M_train, M_test, Delta_train, Delta_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, M_tensor, Delta_tensor, labels, test_size=0.2, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bfb383c98669ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUD, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # GRU weights\n",
    "        self.reset_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.update_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.new_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # Decay parameters\n",
    "        self.gamma_x = nn.Linear(input_size, input_size)\n",
    "        self.gamma_h = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, m, d, h):\n",
    "        # Decay mechanism for inputs\n",
    "        gamma_x = torch.exp(-torch.max(self.gamma_x(d), torch.zeros_like(d)))\n",
    "        x_hat = m * x + (1 - m) * gamma_x * x\n",
    "        \n",
    "        # Decay mechanism for hidden state\n",
    "        d_h = d.mean(dim=1, keepdim=True)\n",
    "        gamma_h = torch.exp(-torch.max(self.gamma_h(d), torch.zeros_like(d_h)))\n",
    "        h_hat = gamma_h * h\n",
    "        \n",
    "        # Concatenate inputs\n",
    "        combined = torch.cat((x_hat, h_hat), dim=1)\n",
    "        \n",
    "        # GRU gates\n",
    "        reset = torch.sigmoid(self.reset_gate(combined))\n",
    "        update = torch.sigmoid(self.update_gate(combined))\n",
    "        new = torch.tanh(self.new_gate(torch.cat((x_hat, reset * h_hat), dim=1)))\n",
    "        \n",
    "        # Compute new hidden state\n",
    "        h_new = (1 - update) * h + update * new\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.fc(h_new)\n",
    "        return out, h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4835b82f9e12bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 38  # The number of input features\n",
    "hidden_size = 64  # Size of the hidden state\n",
    "output_size = 1  # Size of the output\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b407c8c4e1cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, criterion, and optimizer\n",
    "model = GRUD(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca61b039764e29e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUD(\n",
       "  (reset_gate): Linear(in_features=102, out_features=64, bias=True)\n",
       "  (update_gate): Linear(in_features=102, out_features=64, bias=True)\n",
       "  (new_gate): Linear(in_features=102, out_features=64, bias=True)\n",
       "  (gamma_x): Linear(in_features=38, out_features=38, bias=True)\n",
       "  (gamma_h): Linear(in_features=38, out_features=64, bias=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27811dae0ef273ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(torch.tensor(X_tensor, dtype=torch.float32), \n",
    "                              torch.tensor(M_tensor, dtype=torch.float32), \n",
    "                              torch.tensor(Delta_tensor, dtype=torch.float32), \n",
    "                              torch.tensor(labels, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74379dc3b08daf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([16, 336, 38])\n",
      "M_batch shape: torch.Size([16, 336, 38])\n",
      "Delta_batch shape: torch.Size([16, 336, 38])\n",
      "Labels_batch shape: torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    X_batch, M_batch, Delta_batch, labels_batch = batch\n",
    "    print(f'X_batch shape: {X_batch.shape}')\n",
    "    print(f'M_batch shape: {M_batch.shape}')\n",
    "    print(f'Delta_batch shape: {Delta_batch.shape}')\n",
    "    print(f'Labels_batch shape: {labels_batch.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96364e38c7c235e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y_batch)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, M_batch, Delta_batch, y_batch in train_loader:\n",
    "        # Initialize hidden state\n",
    "        h = torch.zeros((X_batch.size(0), hidden_size))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        for t in range(X_batch.size(1)):\n",
    "            x_t = X_batch[:, t, :]\n",
    "            m_t = M_batch[:, t, :]\n",
    "            d_t = Delta_batch[:, t, :]\n",
    "            \n",
    "            output, h = model(x_t, m_t, d_t, h)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822d98c66a5d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), \n",
    "                             torch.tensor(M_test, dtype=torch.float32), \n",
    "                             torch.tensor(Delta_test, dtype=torch.float32), \n",
    "                             torch.tensor(y_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671b0e454bea215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8447ec33081f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, M_batch, Delta_batch, y_batch in test_loader:\n",
    "        # Initialize hidden state\n",
    "        h = torch.zeros((X_batch.size(0), hidden_size))\n",
    "        \n",
    "        # Forward pass\n",
    "        for t in range(X_batch.size(1)):\n",
    "            x_t = X_batch[:, t, :]\n",
    "            m_t = M_batch[:, t, :]\n",
    "            d_t = Delta_batch[:, t, :]\n",
    "            \n",
    "            output, h = model(x_t, m_t, d_t, h)\n",
    "        \n",
    "        # Convert output to binary prediction\n",
    "        predictions = (output >= 0.5).float()\n",
    "        total_correct += (predictions == y_batch).sum().item()\n",
    "        total_samples += y_batch.size(0)\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}